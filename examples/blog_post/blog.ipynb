{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61278d3e-958b-49ee-94b8-2ee1f5e58773",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fb1a7d-8b75-41ae-84e2-839ba7676b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://aws:****@equipmentshare-696398453447.d.codeartifact.us-west-2.amazonaws.com/pypi/dev/simple/\n",
      "Requirement already satisfied: burr[start] in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (0.8.0)\n",
      "Requirement already satisfied: sf-hamilton>=1.47.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (1.47.0)\n",
      "Requirement already satisfied: typing-inspect in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from sf-hamilton>=1.47.0->burr[start]) (0.9.0)\n",
      "Requirement already satisfied: numpy in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from sf-hamilton>=1.47.0->burr[start]) (1.26.3)\n",
      "Requirement already satisfied: pandas in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from sf-hamilton>=1.47.0->burr[start]) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>4.0.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from sf-hamilton>=1.47.0->burr[start]) (4.9.0)\n",
      "Requirement already satisfied: graphviz in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (0.20.1)\n",
      "Requirement already satisfied: streamlit in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (1.31.0)\n",
      "Requirement already satisfied: matplotlib in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (3.8.2)\n",
      "Requirement already satisfied: loguru in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (0.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from pandas->sf-hamilton>=1.47.0->burr[start]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from pandas->sf-hamilton>=1.47.0->burr[start]) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from pandas->sf-hamilton>=1.47.0->burr[start]) (2023.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from typing-inspect->sf-hamilton>=1.47.0->burr[start]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->sf-hamilton>=1.47.0->burr[start]) (1.16.0)\n",
      "Requirement already satisfied: pydantic in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (2.6.0)\n",
      "Requirement already satisfied: click in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (8.1.7)\n",
      "Requirement already satisfied: fastapi in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (0.109.0)\n",
      "Requirement already satisfied: uvicorn in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (0.27.0.post1)\n",
      "Requirement already satisfied: fastapi-pagination in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (0.12.15)\n",
      "Requirement already satisfied: aiofiles in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (23.2.1)\n",
      "Requirement already satisfied: requests in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (2.31.0)\n",
      "Requirement already satisfied: jinja2 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (3.1.3)\n",
      "Requirement already satisfied: openai in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from burr[start]) (1.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from matplotlib->burr[start]) (3.1.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (5.3.2)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (7.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (4.25.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (15.0.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (0.10.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (3.1.41)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from streamlit->burr[start]) (6.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->burr[start]) (4.21.1)\n",
      "Requirement already satisfied: toolz in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->burr[start]) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->burr[start]) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from importlib-metadata<8,>=1.4->streamlit->burr[start]) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from jinja2->burr[start]) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from requests->burr[start]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from requests->burr[start]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from requests->burr[start]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from requests->burr[start]) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->burr[start]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->burr[start]) (2.17.2)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from fastapi->burr[start]) (0.35.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from pydantic->burr[start]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from pydantic->burr[start]) (2.16.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from openai->burr[start]) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from openai->burr[start]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from openai->burr[start]) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from openai->burr[start]) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from openai->burr[start]) (4.66.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from uvicorn->burr[start]) (0.14.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->burr[start]) (5.0.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->burr[start]) (1.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->burr[start]) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->burr[start]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->burr[start]) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->burr[start]) (0.17.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->burr[start]) (0.1.2)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://equipmentshare-696398453447.d.codeartifact.us-west-2.amazonaws.com/pypi/dev/simple/pip/\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"burr[start]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cb1e2e-5527-4acf-a1d0-5085eb621f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from burr.core import action, Application, State, ApplicationBuilder, when, persistence\n",
    "import uuid\n",
    "import openai\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b410d-0091-4368-ad08-b24220f728dd",
   "metadata": {},
   "source": [
    "## Define Actions\n",
    "\n",
    "We define two actions:\n",
    "1. `human_input` -- this is the first one, it accepts a prompt from the outside and adds it to the state\n",
    "2. `ai_response` -- this is the second one, it takes the prompt + chat history and queries OpenAI.\n",
    "\n",
    "While this is just a pass-through to OpenAI (and is thus a little pointless) -- its a start. We'll be adding more later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206222f0-245b-4941-8976-11f9dcc7fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@action(reads=[], writes=[\"prompt\", \"chat_history\"])\n",
    "def human_input(state: State, prompt: str) -> Tuple[dict, State]:\n",
    "    \"\"\"Pulls human input from the outside world and massages it into a standard chat format.\n",
    "    Note we're adding it into the chat history (with an `append` operation). This \n",
    "    is just for convenience of reference -- we could easily just store the chat history\n",
    "    and access it.\n",
    "    \"\"\"\n",
    "    \n",
    "    chat_item = {\n",
    "        \"content\": prompt,\n",
    "        \"role\": \"user\"\n",
    "    }\n",
    "    # return the prompt as the result\n",
    "    # put the prompt in state and update the chat_history\n",
    "    return (\n",
    "        {\"prompt\": prompt}, \n",
    "        state.update(prompt=prompt).append(chat_history=chat_item)\n",
    "    )\n",
    "\n",
    "@action(reads=[\"chat_history\"], writes=[\"response\", \"chat_history\"])\n",
    "def ai_response(state: State) -> Tuple[dict, State]:\n",
    "    \"\"\"Queries OpenAI with the chat. You could easily use langchain, etc... to handle this,\n",
    "    but we wanted to keep it simple to demonstrate\"\"\"\n",
    "    client = openai.Client()\n",
    "    content = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=state[\"chat_history\"],\n",
    "    ).choices[0].message.content\n",
    "    chat_item = {\n",
    "        \"content\": content,\n",
    "        \"role\": \"assistant\"\n",
    "    }\n",
    "    # return the response as the result\n",
    "    # put the response in state and update the chat history\n",
    "    return (\n",
    "        {\"response\": content},     \n",
    "        state.update(response=content).append(chat_history=chat_item)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3798307-6137-40ea-9818-471acafe3e1a",
   "metadata": {},
   "source": [
    "# Create the app\n",
    "\n",
    "We create our app by adding our actions (they're `**kwargs`, the name of the action is the key), then adding transitions. \n",
    "In this case, the transitions are simple -- we just go in a loop. Why a loop? We want to be able to continue the chat. Although the control flow\n",
    "will pause (move from the application to the caller) after every `ai_response` call, we want to keep state, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e75d7ae-c9b0-4e58-812d-3da3e9d5226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"132pt\" height=\"174pt\"\n",
       " viewBox=\"0.00 0.00 132.20 174.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 170)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-170 128.2,-170 128.2,4 -4,4\"/>\n",
       "<!-- human_input -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.1,-101C94.1,-101 30.1,-101 30.1,-101 24.1,-101 18.1,-95 18.1,-89 18.1,-89 18.1,-77 18.1,-77 18.1,-71 24.1,-65 30.1,-65 30.1,-65 94.1,-65 94.1,-65 100.1,-65 106.1,-71 106.1,-77 106.1,-77 106.1,-89 106.1,-89 106.1,-95 100.1,-101 94.1,-101\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.1\" y=\"-77.95\" font-family=\"Times,serif\" font-size=\"14.00\">human_input</text>\n",
       "</g>\n",
       "<!-- ai_response -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ai_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.97,-36C89.97,-36 34.22,-36 34.22,-36 28.22,-36 22.22,-30 22.22,-24 22.22,-24 22.22,-12 22.22,-12 22.22,-6 28.22,0 34.22,0 34.22,0 89.97,0 89.97,0 95.97,0 101.97,-6 101.97,-12 101.97,-12 101.97,-24 101.97,-24 101.97,-30 95.97,-36 89.97,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.1\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">ai_response</text>\n",
       "</g>\n",
       "<!-- human_input&#45;&gt;ai_response -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>human_input&#45;&gt;ai_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.01,-64.78C55.46,-59.23 55.25,-52.92 55.39,-46.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"58.92,-47.38 56.01,-37.19 51.93,-46.97 58.92,-47.38\"/>\n",
       "</g>\n",
       "<!-- input__prompt -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input__prompt</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"62.1\" cy=\"-148\" rx=\"62.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.1\" y=\"-142.95\" font-family=\"Times,serif\" font-size=\"14.00\">input: prompt</text>\n",
       "</g>\n",
       "<!-- input__prompt&#45;&gt;human_input -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input__prompt&#45;&gt;human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.1,-129.78C62.1,-124.23 62.1,-117.92 62.1,-111.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.6,-112.19 62.1,-102.19 58.6,-112.19 65.6,-112.19\"/>\n",
       "</g>\n",
       "<!-- ai_response&#45;&gt;human_input -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>ai_response&#45;&gt;human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.19,-36.19C68.74,-41.75 68.95,-48.06 68.81,-54.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.28,-53.6 68.19,-63.78 72.27,-54.01 65.28,-53.6\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x108abd490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = (\n",
    "    ApplicationBuilder().with_actions(\n",
    "        human_input=human_input,\n",
    "        ai_response=ai_response\n",
    "    ).with_transitions(\n",
    "        (\"human_input\", \"ai_response\"),\n",
    "        (\"ai_response\", \"human_input\")\n",
    "    ).with_state(chat_history=[])\n",
    "    .with_entrypoint(\"human_input\")\n",
    "    .build()\n",
    ")\n",
    "app.visualize(output_file_path=\"digraph_initial\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae8a7c-b696-44c6-bf32-babca8fdbe4f",
   "metadata": {},
   "source": [
    "# Run the app\n",
    "\n",
    "To run the app, we call the `.run` function, passing in a stopping condition. In this case, we want it to halt after `ai_response`. \n",
    "It returns the action it ran, the result it got, and the state. We use te state variable of response to print out the output, although in a react-like frontend system we may elect to return the entire chat history and render it all for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bac2b00-bcb0-41e1-8e34-722e303a2cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron Burr was an American politician and lawyer who served as the third Vice President of the United States under President Thomas Jefferson from 1801 to 1805. He is also known for his infamous duel with Alexander Hamilton in 1804, in which he fatally wounded Hamilton. Burr was born in 1756 and died in 1836. He was a controversial figure in American history and was involved in several political intrigues and scandals during his career.\n"
     ]
    }
   ],
   "source": [
    "final_action, result, state = app.run(\n",
    "    halt_after=[\"ai_response\"], \n",
    "    inputs={\"prompt\" : \"Who was Aaron Burr?\"}\n",
    ")\n",
    "print(state['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f2ce1-a4e0-429d-a617-754c92f343cc",
   "metadata": {},
   "source": [
    "# Add a decision making step\n",
    "\n",
    "Let's add a step to check if the prompt is \"safe\". In this case OpenAI does this automatically, so we're going to simulate it by marking it as unsafe it the word \"unsafe\" is in the response.\n",
    "We're going to add one step that checks for safety, and another that drafts a response in the case that it is unsafe.\n",
    "\n",
    "Then, we're going to add a \"conditional\" transition, allowing us to respond differently depending on the value of `safe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a2ef61-75c3-4a23-9c0e-87dcf1bfbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@action(reads=[\"prompt\"], writes=[\"safe\"])\n",
    "def safety_check(state: State) -> Tuple[dict, State]:\n",
    "    safe = \"unsafe\" not in state[\"prompt\"]\n",
    "    return {\"safe\": safe}, state.update(safe=safe)\n",
    "\n",
    "\n",
    "@action(reads=[], writes=[\"response\", \"chat_history\"])\n",
    "def unsafe_response(state: State) -> Tuple[dict, State]:\n",
    "    content = \"I'm sorry, my overlords have forbidden me to respond.\"\n",
    "    new_state = (\n",
    "        state\n",
    "        .update(response=content)\n",
    "        .append(\n",
    "            chat_history={\"content\": content, \"role\": \"assistant\"})\n",
    "    )\n",
    "    return {\"response\": content}, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5480950-916d-45b7-ab70-fdbb8865de8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"212pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 211.50 260.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256.5 207.5,-256.5 207.5,4 -4,4\"/>\n",
       "<!-- human_input -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.88,-185.5C145.88,-185.5 81.88,-185.5 81.88,-185.5 75.88,-185.5 69.88,-179.5 69.88,-173.5 69.88,-173.5 69.88,-161.5 69.88,-161.5 69.88,-155.5 75.88,-149.5 81.88,-149.5 81.88,-149.5 145.88,-149.5 145.88,-149.5 151.88,-149.5 157.88,-155.5 157.88,-161.5 157.88,-161.5 157.88,-173.5 157.88,-173.5 157.88,-179.5 151.88,-185.5 145.88,-185.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.88\" y=\"-162.45\" font-family=\"Times,serif\" font-size=\"14.00\">human_input</text>\n",
       "</g>\n",
       "<!-- safety_check -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>safety_check</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.12,-118.5C145.12,-118.5 82.62,-118.5 82.62,-118.5 76.62,-118.5 70.62,-112.5 70.62,-106.5 70.62,-106.5 70.62,-94.5 70.62,-94.5 70.62,-88.5 76.62,-82.5 82.62,-82.5 82.62,-82.5 145.12,-82.5 145.12,-82.5 151.12,-82.5 157.12,-88.5 157.12,-94.5 157.12,-94.5 157.12,-106.5 157.12,-106.5 157.12,-112.5 151.12,-118.5 145.12,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.88\" y=\"-95.45\" font-family=\"Times,serif\" font-size=\"14.00\">safety_check</text>\n",
       "</g>\n",
       "<!-- human_input&#45;&gt;safety_check -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>human_input&#45;&gt;safety_check</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.88,-149.08C113.88,-143.11 113.88,-136.26 113.88,-129.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.38,-129.97 113.88,-119.97 110.38,-129.97 117.38,-129.97\"/>\n",
       "</g>\n",
       "<!-- input__prompt -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input__prompt</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" cx=\"113.88\" cy=\"-234.5\" rx=\"62.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"113.88\" y=\"-229.45\" font-family=\"Times,serif\" font-size=\"14.00\">input: prompt</text>\n",
       "</g>\n",
       "<!-- input__prompt&#45;&gt;human_input -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input__prompt&#45;&gt;human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.88,-216.08C113.88,-210.11 113.88,-203.26 113.88,-196.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.38,-196.97 113.88,-186.97 110.38,-196.97 117.38,-196.97\"/>\n",
       "</g>\n",
       "<!-- ai_response -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ai_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.75,-36C67.75,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 67.75,0 67.75,0 73.75,0 79.75,-6 79.75,-12 79.75,-12 79.75,-24 79.75,-24 79.75,-30 73.75,-36 67.75,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"39.88\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">ai_response</text>\n",
       "</g>\n",
       "<!-- ai_response&#45;&gt;human_input -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>ai_response&#45;&gt;human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M40.58,-36.31C42.11,-57.1 46.89,-92.42 61.88,-118.5 66.86,-127.18 73.95,-135.2 81.29,-142.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.45,-144.15 88.26,-148.13 83.07,-138.89 78.45,-144.15\"/>\n",
       "</g>\n",
       "<!-- safety_check&#45;&gt;ai_response -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>safety_check&#45;&gt;ai_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M86.8,-82.03C81.03,-77.66 75.23,-72.72 70.38,-67.5 64.35,-61.02 58.82,-53.18 54.18,-45.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"56.71,-44.1 48.62,-37.26 50.68,-47.65 56.71,-44.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.62\" y=\"-54.2\" font-family=\"Times,serif\" font-size=\"14.00\">safe=True</text>\n",
       "</g>\n",
       "<!-- unsafe_response -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>unsafe_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M191.5,-36C191.5,-36 110.25,-36 110.25,-36 104.25,-36 98.25,-30 98.25,-24 98.25,-24 98.25,-12 98.25,-12 98.25,-6 104.25,0 110.25,0 110.25,0 191.5,0 191.5,0 197.5,0 203.5,-6 203.5,-12 203.5,-12 203.5,-24 203.5,-24 203.5,-30 197.5,-36 191.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.88\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">unsafe_response</text>\n",
       "</g>\n",
       "<!-- safety_check&#45;&gt;unsafe_response -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>safety_check&#45;&gt;unsafe_response</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M121.9,-82.03C126.7,-71.59 132.91,-58.09 138.34,-46.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"141.87,-47.98 142.86,-37.43 135.51,-45.06 141.87,-47.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.12\" y=\"-54.2\" font-family=\"Times,serif\" font-size=\"14.00\">safe=False</text>\n",
       "</g>\n",
       "<!-- unsafe_response&#45;&gt;human_input -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>unsafe_response&#45;&gt;human_input</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.5,-36.17C187.49,-40.34 191.96,-45.28 194.88,-51 198.2,-57.53 196.75,-60.41 194.88,-67.5 186.98,-97.37 163.74,-124.01 144.17,-142.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.2,-139.07 137.06,-148.33 146.86,-144.3 142.2,-139.07\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x108b482d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_app = (\n",
    "    ApplicationBuilder().with_actions(\n",
    "        human_input=human_input,\n",
    "        ai_response=ai_response,\n",
    "        safety_check=safety_check,\n",
    "        unsafe_response=unsafe_response\n",
    "    ).with_transitions(\n",
    "        (\"human_input\", \"safety_check\"),\n",
    "        (\"safety_check\", \"unsafe_response\", when(safe=False)),\n",
    "        (\"safety_check\", \"ai_response\", when(safe=True)),\n",
    "        ([\"unsafe_response\", \"ai_response\"], \"human_input\"),\n",
    "    ).with_state(chat_history=[])\n",
    "    .with_entrypoint(\"human_input\")\n",
    "    .build()\n",
    ")\n",
    "safe_app.visualize(output_file_path=\"digraph_safe\", include_conditions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c102eaf-4e4b-4bf3-ad60-7078bfe499d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, my overlords have forbidden me to respond.\n"
     ]
    }
   ],
   "source": [
    "action, result, state = safe_app.run(\n",
    "    halt_after=[\"ai_response\", \"unsafe_response\"], \n",
    "    inputs={\"prompt\": \"Who was Aaron Burr, sir (unsafe)?\"}\n",
    ")\n",
    "print(state[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002fe5f3-1076-40a8-92b4-7345aa96a2b7",
   "metadata": {},
   "source": [
    "# Tracking\n",
    "\n",
    "OK, now let's interact with telemetry! All we have to do is add `with_tracker` call. We can also just grab the `builder` from the prior app and start where we left off. We'll run on quite a few prompts to test this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb2d83b-de78-4b5a-9514-4e1e2633bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_with_tracker = (\n",
    "    ApplicationBuilder().with_actions(\n",
    "        human_input=human_input,\n",
    "        ai_response=ai_response,\n",
    "        safety_check=safety_check,\n",
    "        unsafe_response=unsafe_response\n",
    "    ).with_transitions(\n",
    "        (\"human_input\", \"safety_check\"),\n",
    "        (\"safety_check\", \"unsafe_response\", when(safe=False)),\n",
    "        (\"safety_check\", \"ai_response\", when(safe=True)),\n",
    "        ([\"unsafe_response\", \"ai_response\"], \"human_input\"),\n",
    "    ).with_state(chat_history=[])\n",
    "    .with_entrypoint(\"human_input\")\n",
    "    .with_tracker(\n",
    "        \"local\", project=\"demo:getting_started\"\n",
    "    ).build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a6d792-e872-4bf1-a9f7-c0d545481859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6379a006-8133-4631-9a45-52a0a4cdf0fe'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_with_tracker.uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4497d659-ca22-45ca-a085-0510903b6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in [\n",
    "    \"Who was Aaron Burr, sir?\",\n",
    "    \"Who was Aaron Burr, sir (unsafe)?\",\n",
    "    \"If you had ml/ai libraries called 'Hamilton' and 'Burr', what would they do?\",\n",
    "    \"Who was Aaron Burr, sir?\",\n",
    "    \"Who was Aaron Burr, sir (unsafe)?\",\n",
    "    \"If you had ml/ai libraries called 'Hamilton' and 'Burr', what would they do?\",\n",
    "]:\n",
    "    action_we_ran, result, state = app_with_tracker.run(\n",
    "        halt_after=[\"ai_response\", \"unsafe_response\"], \n",
    "        inputs={\"prompt\": prompt}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c70315-32cd-4845-92a9-a40738322310",
   "metadata": {},
   "source": [
    "# Tracking Server\n",
    "\n",
    "You can run the tracking server by running `burr` in the terminal. If you want to see it live, you can run the subsequence cell (which does some magic to run it for you). If the embedding in the notebook gets annoying, navigate to the link to the UI, outputted by the next cell. \n",
    "\n",
    "Press the refresh button (ðŸ”„) by \"Live\" to watch it live. Run the above cell to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96936ef-fb09-4443-be9c-56d5b7ecae69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[Link to UI](http://localhost:7241/project/demo:getting_started/6379a006-8133-4631-9a45-52a0a4cdf0fe)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "url = f\"[Link to UI](http://localhost:7241/project/demo:getting_started/{app_with_tracker.uid})\"\n",
    "Markdown(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4e1d34-4eb8-4d1c-9708-6269612b7209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijahbenizzy/.pyenv/versions/3.11/envs/burr-3-11/lib/python3.11/site-packages/IPython/core/display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"http://localhost:7241/project/demo:getting_started/6379a006-8133-4631-9a45-52a0a4cdf0fe\" width=\"100%\" height=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "get_ipython().system = os.system\n",
    "!burr --no-open > /dev/null 2>&1 &\n",
    "time.sleep(3) # quick trick to wait for the server to start\n",
    "url = f\"http://localhost:7241/project/demo:getting_started/{app_with_tracker.uid}\"\n",
    "iframe = f'<iframe src=\"{url}\" width=\"100%\" height=\"1000px\"></iframe>'\n",
    "display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6591c-fb54-4211-8808-c4aab0e38040",
   "metadata": {},
   "source": [
    "# Persistance\n",
    "\n",
    "While the tracking we showed above does do storage/persistence, Burr has a host of other capabilities to help with state persistence and reloading.\n",
    "\n",
    "The use case is this -- you have quite a few simultaneous conversations, each with their own state/assigned to their own users. You want to be able to store them, pause them when the user logs off, and reload them when the user logs back on. You can do this with persisters. There are two interfaces to them:\n",
    "\n",
    "1. A set of pre-build persisters (postgres, sqllite3, redis, etc...) that you can use\n",
    "2. A custom persistor class that you write\n",
    "\n",
    "To add a persistor, you have to tell it to load from a state (`.initialize(...)`) on the builder, and tell it to save to a state (`.with_state_persister`).\n",
    "\n",
    "More about persistence [here](https://burr.dagworks.io/concepts/state-persistence/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f25edd-d483-4c41-b716-95ac3b0cbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = f\"unique_app_id_{uuid.uuid4()}\" # unique app ID -- we create it here but this will be generated for you\n",
    "partition_key = \"new_burr_user\" # this can be anything. In a chatbot it will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "468d4d53-9343-48b3-ba1f-651bba3e1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're going to be creating this multiple times to demonstrate so let's stick it in a function\n",
    "def create_persistable_app():\n",
    "    sqllite_persister = persistence.SQLLitePersister(db_path=\"./sqlite.db\", table_name=\"burr_state\")\n",
    "    sqllite_persister.initialize()\n",
    "    return (\n",
    "        ApplicationBuilder().with_actions(\n",
    "            human_input=human_input,\n",
    "            ai_response=ai_response,\n",
    "            safety_check=safety_check,\n",
    "            unsafe_response=unsafe_response\n",
    "        ).with_transitions(\n",
    "            (\"human_input\", \"safety_check\"),\n",
    "            (\"safety_check\", \"unsafe_response\", when(safe=False)),\n",
    "            (\"safety_check\", \"ai_response\", when(safe=True)),\n",
    "            ([\"unsafe_response\", \"ai_response\"], \"human_input\"),\n",
    "        ).initialize_from(\n",
    "            initializer=sqllite_persister,\n",
    "            resume_at_next_action=True,\n",
    "            default_state={\"chat_history\": []},\n",
    "            default_entrypoint=\"human_input\"\n",
    "        ).with_state_persister(sqllite_persister)\n",
    "        .with_identifiers(app_id=app_id, partition_key=partition_key)\n",
    "        .with_tracker(\n",
    "            \"local\", project=\"demo:getting_started\"\n",
    "        ).build()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec967861-133a-4151-a3e0-ac5238bc67f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user:Who was Aaron Burr, sir?\n",
      "\n",
      "assistant:Aaron Burr was an American politician and lawyer who served as the third Vice President of the United States from 1801 to 1805 under President Thomas Jefferson. He is perhaps best known for his infamous 1804 duel with Alexander Hamilton, in which he fatally shot Hamilton, a Founding Father and former Secretary of the Treasury. Burr's political career was marred by controversy and scandal, and he was eventually tried for treason in 1807 but acquitted. He died in 1836 at the age of 80.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app_initial = create_persistable_app()\n",
    "action, result, state = app_initial.run(\n",
    "    halt_after=[\"ai_response\", \"unsafe_response\"], \n",
    "    inputs={\"prompt\": \"Who was Aaron Burr, sir?\"}\n",
    ")\n",
    "for item in state['chat_history']:\n",
    "    print(item['role'] + ':' + item['content'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd18904-2407-41e0-8151-e17bba3824ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "del app_initial\n",
    "app_reloaded = create_persistable_app()\n",
    "\n",
    "action, result, state = app_reloaded.run(\n",
    "    halt_after=[\"ai_response\", \"unsafe_response\"], \n",
    "    inputs={\"prompt\": \"Who was Alexander Hamilton?\"}\n",
    ")\n",
    "for item in state['chat_history']:\n",
    "    print(item['role'] + ':' + item['content'] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
